# PostgreSQL Configuration for Beyond the AI Plateau Production Environment
# Optimized for high-performance learning platform workloads

#------------------------------------------------------------------------------
# FILE LOCATIONS
#------------------------------------------------------------------------------

data_directory = '/var/lib/postgresql/data'
hba_file = '/var/lib/postgresql/data/pg_hba.conf'
ident_file = '/var/lib/postgresql/data/pg_ident.conf'
external_pid_file = '/var/run/postgresql/postgres.pid'

#------------------------------------------------------------------------------
# CONNECTIONS AND AUTHENTICATION
#------------------------------------------------------------------------------

# Connection Settings
listen_addresses = '*'
port = 5432
max_connections = 200
superuser_reserved_connections = 3

# Authentication
authentication_timeout = 1min
password_encryption = scram-sha-256
ssl = on
ssl_cert_file = '/etc/ssl/certs/ssl-cert-snakeoil.pem'
ssl_key_file = '/etc/ssl/private/ssl-cert-snakeoil.key'

#------------------------------------------------------------------------------
# RESOURCE USAGE (except WAL)
#------------------------------------------------------------------------------

# Memory Settings (optimized for 8GB RAM server)
shared_buffers = 2GB                    # 25% of total RAM
effective_cache_size = 6GB              # 75% of total RAM
work_mem = 64MB                         # For complex queries
maintenance_work_mem = 512MB            # For maintenance operations
temp_buffers = 32MB                     # Temporary tables

# Background Writer
bgwriter_delay = 200ms
bgwriter_lru_maxpages = 100
bgwriter_lru_multiplier = 2.0
bgwriter_flush_after = 512kB

# Asynchronous Behavior
effective_io_concurrency = 200          # For SSD storage
random_page_cost = 1.1                  # SSD optimized
seq_page_cost = 1.0

#------------------------------------------------------------------------------
# WRITE AHEAD LOG
#------------------------------------------------------------------------------

# WAL Settings
wal_level = replica
wal_buffers = 16MB
wal_compression = on
wal_log_hints = on

# Checkpoints
checkpoint_timeout = 10min
checkpoint_completion_target = 0.9
max_wal_size = 2GB
min_wal_size = 512MB
checkpoint_flush_after = 256kB

# Archiving
archive_mode = on
archive_command = 'cp %p /data/amysoft/postgres/archive/%f'
archive_timeout = 1800                  # 30 minutes

#------------------------------------------------------------------------------
# REPLICATION
#------------------------------------------------------------------------------

# Streaming Replication (for future scaling)
max_wal_senders = 3
max_replication_slots = 3
wal_keep_size = 1GB
hot_standby = on
hot_standby_feedback = on

#------------------------------------------------------------------------------
# QUERY TUNING
#------------------------------------------------------------------------------

# Planner Cost Constants
cpu_tuple_cost = 0.01
cpu_index_tuple_cost = 0.005
cpu_operator_cost = 0.0025

# Planner Method Configuration
enable_hashagg = on
enable_hashjoin = on
enable_indexscan = on
enable_indexonlyscan = on
enable_material = on
enable_mergejoin = on
enable_nestloop = on
enable_parallel_append = on
enable_parallel_hash = on
enable_seqscan = on
enable_sort = on
enable_tidscan = on

# Genetic Query Optimizer
geqo = on
geqo_threshold = 12
geqo_effort = 5
geqo_pool_size = 0
geqo_generations = 0
geqo_selection_bias = 2.0
geqo_seed = 0.0

# Other Planner Options
default_statistics_target = 100
constraint_exclusion = partition
cursor_tuple_fraction = 0.1
from_collapse_limit = 8
join_collapse_limit = 8
force_parallel_mode = off

#------------------------------------------------------------------------------
# REPORTING AND LOGGING
#------------------------------------------------------------------------------

# Where to Log
log_destination = 'stderr,csvlog'
logging_collector = on
log_directory = '/var/log/postgresql'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_file_mode = 0600
log_truncate_on_rotation = on
log_rotation_age = 1d
log_rotation_size = 100MB

# When to Log
log_min_messages = warning
log_min_error_statement = error
log_min_duration_statement = 1000        # Log slow queries (1 second)

# What to Log
debug_print_parse = off
debug_print_rewritten = off
debug_print_plan = off
debug_pretty_print = on
log_checkpoints = on
log_connections = on
log_disconnections = on
log_duration = off
log_error_verbosity = default
log_hostname = off
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_lock_waits = on
log_statement = 'ddl'
log_replication_commands = off
log_temp_files = 10MB

#------------------------------------------------------------------------------
# RUNTIME STATISTICS
#------------------------------------------------------------------------------

# Query/Index Statistics Collector
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all
track_activity_query_size = 1024
stats_temp_directory = '/var/run/postgresql/stats_temp'

# Statistics Monitoring
log_parser_stats = off
log_planner_stats = off
log_executor_stats = off
log_statement_stats = off

#------------------------------------------------------------------------------
# AUTOVACUUM PARAMETERS
#------------------------------------------------------------------------------

# Autovacuum Settings (optimized for high-write learning platform)
autovacuum = on
log_autovacuum_min_duration = 0
autovacuum_max_workers = 4
autovacuum_naptime = 30s
autovacuum_vacuum_threshold = 50
autovacuum_analyze_threshold = 50
autovacuum_vacuum_scale_factor = 0.1     # More aggressive for high-activity tables
autovacuum_analyze_scale_factor = 0.05   # More frequent analyze
autovacuum_freeze_max_age = 200000000
autovacuum_multixact_freeze_max_age = 400000000
autovacuum_vacuum_cost_delay = 10ms
autovacuum_vacuum_cost_limit = 200

#------------------------------------------------------------------------------
# CLIENT CONNECTION DEFAULTS
#------------------------------------------------------------------------------

# Statement Behavior
search_path = '"$user", public'
row_security = on
default_tablespace = ''
temp_tablespaces = ''
default_table_access_method = 'heap'

# Locale and Formatting
datestyle = 'iso, mdy'
intervalstyle = 'postgres'
timezone = 'UTC'
timezone_abbreviations = 'Default'
extra_float_digits = 1
client_encoding = utf8

# Shared Library Preloading
shared_preload_libraries = 'pg_stat_statements,auto_explain'

#------------------------------------------------------------------------------
# LOCK MANAGEMENT
#------------------------------------------------------------------------------

deadlock_timeout = 1s
max_locks_per_transaction = 64
max_pred_locks_per_transaction = 64
max_pred_locks_per_relation = -2
max_pred_locks_per_page = 2

#------------------------------------------------------------------------------
# ERROR HANDLING
#------------------------------------------------------------------------------

exit_on_error = off
restart_after_crash = on
data_sync_retry = off

#------------------------------------------------------------------------------
# CONFIG FILE INCLUDES
#------------------------------------------------------------------------------

# Include files for additional configuration
include_dir = 'conf.d'

#------------------------------------------------------------------------------
# CUSTOMIZED OPTIONS FOR LEARNING PLATFORM
#------------------------------------------------------------------------------

# Extensions Configuration
pg_stat_statements.max = 10000
pg_stat_statements.track = all
pg_stat_statements.save = on

# Auto Explain for Slow Queries
auto_explain.log_min_duration = 5000     # 5 seconds
auto_explain.log_analyze = on
auto_explain.log_verbose = on
auto_explain.log_buffers = on
auto_explain.log_timing = on
auto_explain.log_triggers = on
auto_explain.log_nested_statements = on

# Parallel Query Settings
max_parallel_workers_per_gather = 4
max_parallel_maintenance_workers = 4
max_parallel_workers = 8
parallel_tuple_cost = 0.1
parallel_setup_cost = 1000.0
min_parallel_table_scan_size = 8MB
min_parallel_index_scan_size = 512kB

# JIT Settings (for complex analytical queries)
jit = on
jit_above_cost = 100000
jit_inline_above_cost = 500000
jit_optimize_above_cost = 500000

#------------------------------------------------------------------------------
# SPECIFIC OPTIMIZATIONS FOR LEARNING PLATFORM WORKLOADS
#------------------------------------------------------------------------------

# Content Delivery Optimization
# Optimize for frequent reads of chapter content and user progress
synchronous_commit = off               # Improved write performance for analytics
commit_delay = 100000                  # Batch commits for better throughput
commit_siblings = 5

# Session and Connection Pooling
tcp_keepalives_idle = 600
tcp_keepalives_interval = 30
tcp_keepalives_count = 3

# Memory for Complex Analytical Queries
huge_pages = try
max_stack_depth = 7MB

# Locale Settings for International Users
lc_messages = 'en_US.UTF-8'
lc_monetary = 'en_US.UTF-8'
lc_numeric = 'en_US.UTF-8'
lc_time = 'en_US.UTF-8'
default_text_search_config = 'pg_catalog.english'

# Vacuum and Analyze Settings for High-Activity Tables
vacuum_cost_delay = 0                  # Aggressive vacuum for production
vacuum_cost_page_hit = 1
vacuum_cost_page_miss = 10
vacuum_cost_page_dirty = 20
vacuum_cost_limit = 200

# Statement Timeout for Long-Running Queries
statement_timeout = 300000             # 5 minutes
lock_timeout = 30000                   # 30 seconds
idle_in_transaction_session_timeout = 600000  # 10 minutes

# Logging for Performance Monitoring
log_executor_stats = off
log_statement_stats = off
log_btree_build_stats = off

# Hot Standby Settings for Read Replicas
max_standby_archive_delay = 30s
max_standby_streaming_delay = 30s
wal_receiver_status_interval = 10s
hot_standby_feedback = on
wal_receiver_timeout = 60s
wal_retrieve_retry_interval = 5s

#------------------------------------------------------------------------------
# CUSTOM SETTINGS FOR SPECIFIC TABLES
#------------------------------------------------------------------------------

# These will be applied via ALTER TABLE commands in migration scripts:
# 
# High-frequency tables (user_sessions, analytics_events):
# - autovacuum_vacuum_scale_factor = 0.05
# - autovacuum_analyze_scale_factor = 0.02
# - fillfactor = 85
#
# Content tables (chapters, templates):
# - autovacuum_vacuum_scale_factor = 0.2
# - autovacuum_analyze_scale_factor = 0.1
# - fillfactor = 95
#
# User data (users, subscriptions):
# - autovacuum_vacuum_scale_factor = 0.1
# - autovacuum_analyze_scale_factor = 0.05
# - fillfactor = 90
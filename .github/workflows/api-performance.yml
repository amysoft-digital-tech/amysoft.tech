name: API Performance Monitoring

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      duration:
        description: 'Test duration in minutes'
        required: true
        default: '5'
        type: string

env:
  NODE_VERSION: '20'

jobs:
  performance-test:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'staging' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install performance testing tools
        run: |
          npm install -g artillery@latest
          npm install -g clinic

      - name: Run API performance tests
        run: |
          echo "Running performance tests against ${{ github.event.inputs.environment || 'staging' }} environment"
          
          # Create artillery configuration
          cat > artillery-config.yml << EOF
          config:
            target: '${{ secrets.API_BASE_URL || 'https://api-staging.amysoft.tech' }}'
            phases:
              - duration: ${{ github.event.inputs.duration || '5' }}
                arrivalRate: 10
                name: "Sustained load"
              - duration: 2
                arrivalRate: 50
                name: "Peak load"
            headers:
              Authorization: 'Bearer ${{ secrets.TEST_API_TOKEN }}'
          scenarios:
            - name: "API Health Check"
              weight: 20
              flow:
                - get:
                    url: "/health"
            - name: "Authentication Flow"
              weight: 30
              flow:
                - post:
                    url: "/auth/login"
                    json:
                      email: "test@example.com"
                      password: "test-password"
                    capture:
                      - json: "$.token"
                        as: "authToken"
                - get:
                    url: "/auth/profile"
                    headers:
                      Authorization: "Bearer {{ authToken }}"
            - name: "Content API"
              weight: 40
              flow:
                - get:
                    url: "/content/chapters"
                - get:
                    url: "/content/templates"
                    qs:
                      limit: 20
                      category: "productivity"
            - name: "User Analytics"
              weight: 10
              flow:
                - get:
                    url: "/analytics/user-progress"
                - post:
                    url: "/analytics/track-event"
                    json:
                      event: "chapter_completed"
                      metadata:
                        chapter_id: "1"
                        duration: 1800
          EOF
          
          # Run artillery performance test
          artillery run artillery-config.yml --output performance-report.json

      - name: Generate performance report
        run: |
          artillery report performance-report.json --output performance-report.html
          
          # Extract key metrics
          echo "## Performance Test Results" > performance-summary.md
          echo "**Environment:** ${{ github.event.inputs.environment || 'staging' }}" >> performance-summary.md
          echo "**Duration:** ${{ github.event.inputs.duration || '5' }} minutes" >> performance-summary.md
          echo "**Timestamp:** $(date -u)" >> performance-summary.md
          echo "" >> performance-summary.md
          
          # Parse results and add to summary
          node -e "
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('performance-report.json', 'utf8'));
            const aggregate = report.aggregate;
            
            console.log('### Key Metrics');
            console.log('| Metric | Value |');
            console.log('|--------|--------|');
            console.log(\`| Total Requests | \${aggregate.counters['http.requests'] || 0} |\`);
            console.log(\`| Successful Requests | \${aggregate.counters['http.codes.200'] || 0} |\`);
            console.log(\`| Failed Requests | \${aggregate.counters['http.codes.4xx'] + aggregate.counters['http.codes.5xx'] || 0} |\`);
            console.log(\`| Average Response Time | \${Math.round(aggregate.latency?.mean || 0)}ms |\`);
            console.log(\`| 95th Percentile | \${Math.round(aggregate.latency?.p95 || 0)}ms |\`);
            console.log(\`| 99th Percentile | \${Math.round(aggregate.latency?.p99 || 0)}ms |\`);
            console.log(\`| Requests/Second | \${Math.round(aggregate.rates?.mean || 0)} |\`);
            console.log(\`| Error Rate | \${Math.round(((aggregate.counters['http.codes.4xx'] + aggregate.counters['http.codes.5xx']) / aggregate.counters['http.requests']) * 100 || 0)}% |\`);
          " >> performance-summary.md

      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results-${{ github.event.inputs.environment || 'staging' }}-${{ github.run_number }}
          path: |
            performance-report.json
            performance-report.html
            performance-summary.md
          retention-days: 30

      - name: Comment performance results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('performance-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## 🚀 API Performance Test Results\n\n${summary}`
            });

  database-performance:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: performance_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup test database with large dataset
        run: |
          # Run migrations
          npx nx run api:db:migrate
          
          # Generate large test dataset
          npx nx run api:db:seed:performance
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/performance_test

      - name: Run database performance tests
        run: |
          echo "Running database performance tests..."
          
          # Test query performance
          npx nx run api:test:db-performance
          
          # Generate database performance report
          echo "## Database Performance Test Results" > db-performance-summary.md
          echo "**Test Database:** PostgreSQL 15" >> db-performance-summary.md
          echo "**Dataset Size:** Large (production-like)" >> db-performance-summary.md
          echo "**Timestamp:** $(date -u)" >> db-performance-summary.md
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/performance_test

      - name: Upload database performance results
        uses: actions/upload-artifact@v4
        with:
          name: database-performance-results-${{ github.run_number }}
          path: db-performance-summary.md
          retention-days: 30

  api-monitoring:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    steps:
      - name: Check API health endpoints
        run: |
          echo "Checking API health across environments..."
          
          # Check staging health
          echo "## API Health Check Results" > health-check-results.md
          echo "**Timestamp:** $(date -u)" >> health-check-results.md
          echo "" >> health-check-results.md
          
          # Staging health check
          if curl -f -s "${{ secrets.STAGING_API_URL }}/health" > /dev/null; then
            echo "✅ **Staging API:** Healthy" >> health-check-results.md
          else
            echo "❌ **Staging API:** Unhealthy" >> health-check-results.md
          fi
          
          # Production health check (if configured)
          if [ -n "${{ secrets.PRODUCTION_API_URL }}" ]; then
            if curl -f -s "${{ secrets.PRODUCTION_API_URL }}/health" > /dev/null; then
              echo "✅ **Production API:** Healthy" >> health-check-results.md
            else
              echo "❌ **Production API:** Unhealthy" >> health-check-results.md
            fi
          fi

      - name: Check database connectivity
        run: |
          echo "" >> health-check-results.md
          echo "### Database Connectivity" >> health-check-results.md
          
          # Test database connections (using health endpoints)
          if curl -f -s "${{ secrets.STAGING_API_URL }}/health/database" > /dev/null; then
            echo "✅ **Staging Database:** Connected" >> health-check-results.md
          else
            echo "❌ **Staging Database:** Connection issues" >> health-check-results.md
          fi

      - name: Upload health check results
        uses: actions/upload-artifact@v4
        with:
          name: health-check-results-${{ github.run_number }}
          path: health-check-results.md
          retention-days: 7

      - name: Notify on health check failures
        if: failure()
        run: |
          echo "Health check failed - notifications would be sent here"
          # Add notification logic (Slack, PagerDuty, etc.)

  performance-benchmarks:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run comprehensive benchmark suite
        run: |
          echo "Running comprehensive API benchmark suite..."
          
          # Create comprehensive benchmark configuration
          cat > benchmark-config.yml << EOF
          config:
            target: '${{ secrets.API_BASE_URL || 'https://api-staging.amysoft.tech' }}'
            phases:
              - duration: 60
                arrivalRate: 1
                name: "Baseline"
              - duration: 300
                arrivalRate: 10
                name: "Normal load"
              - duration: 120
                arrivalRate: 25
                name: "High load"
              - duration: 60
                arrivalRate: 50
                name: "Peak load"
              - duration: 30
                arrivalRate: 100
                name: "Stress test"
            processor: "./benchmark-processor.js"
          scenarios:
            - name: "Authentication Performance"
              weight: 20
              flow:
                - post:
                    url: "/auth/login"
                    json:
                      email: "perf-test@example.com"
                      password: "performance-test"
            - name: "Content Delivery Performance"
              weight: 40
              flow:
                - get:
                    url: "/content/chapters"
                - get:
                    url: "/content/templates"
                    qs:
                      limit: 50
            - name: "Analytics Performance"
              weight: 30
              flow:
                - get:
                    url: "/analytics/dashboard"
                - post:
                    url: "/analytics/events"
                    json:
                      events: [
                        {
                          type: "page_view",
                          timestamp: "{{ \$timestamp }}"
                        }
                      ]
            - name: "Search Performance"
              weight: 10
              flow:
                - get:
                    url: "/search/content"
                    qs:
                      q: "productivity tips"
                      limit: 20
          EOF
          
          # Run comprehensive benchmark
          artillery run benchmark-config.yml --output comprehensive-benchmark.json

      - name: Generate benchmark report
        run: |
          artillery report comprehensive-benchmark.json --output comprehensive-benchmark.html
          
          echo "## Comprehensive API Benchmark Results" > benchmark-summary.md
          echo "**Environment:** ${{ github.event.inputs.environment || 'staging' }}" >> benchmark-summary.md
          echo "**Duration:** 9.5 minutes (full suite)" >> benchmark-summary.md
          echo "**Timestamp:** $(date -u)" >> benchmark-summary.md

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-benchmark-results-${{ github.run_number }}
          path: |
            comprehensive-benchmark.json
            comprehensive-benchmark.html
            benchmark-summary.md
          retention-days: 30